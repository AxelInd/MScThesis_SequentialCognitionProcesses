\chapter{Mathematical Preliminaries}\label{chp:prelim} 
\section{Propositional Logic}

\begin{table}
\begin{center}


\begin{tabular}{ c | c c }
  $\land$& $\top$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $\bot$ \\  
 $\bot$ & $\bot$ &  $\bot$
\end{tabular}
\quad
\begin{tabular}{ c | c c }
  $\lor$& $\top$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $\top$ \\  
 $\bot$ & $\top$ &  $\bot$
\end{tabular}
\quad
\begin{tabular}{ c | c }
  $\lnot$& \\ \hline
 $\top$ & $\bot$ \\  
 $\bot$ & $\top$
\end{tabular}

\begin{tabular}{ c | c c }
  $\rightarrow$& $\top$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $\bot$ \\  
 $\bot$ & $\top$ &  $\top$
\end{tabular}
\quad
\begin{tabular}{ c | c c }
  $\leftarrow$& $\top$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $\bot$ \\  
 $\bot$ & $\top$ &  $\top$
\end{tabular}

\caption{Truth tables for standard operators in propositional logic.}
\label{tbl:prop}

\end{center}
\end{table}

Propositional logic is one of the simplest classical logics and concerns itself with binary truth values. $\top$ denotes a tautology, and $\bot$ denotes a contradiction. An alphabet $\Sigma=\{v_1,...,v_n\}$ defines the set of atoms available to the language. Every atom $v_i \in \Sigma$ has the domain $\{v_i, \bar{v_i}\}$. An (atom, domain) pair which associates an atom with a value in its domain is called a literal.

A formula $\theta \in \zeta$ from set of all formuli $\zeta$ is defined recursively over all conjunction $\land$, disjunction $\lor$, and negation $\lnot$ operations as follows:

\[
\theta = \{ v_i \in \Sigma | \lnot \theta | \theta \lor \theta | \theta \land \theta \}
\]


The material implication $(\psi \leftarrow \phi)$ precisely substitutes the formula for the formula $(\lnot \psi \lor \phi)$ and is often used, classically to denote an ``if $\phi$ then $\psi$" relationship between variables. However, in Section~@TODOref other interpretations of the "if $\phi$ then $\psi$" relationship are examined in a non-monotonic setting.

An interpretation of $\Sigma$, $I_w(\Sigma)$ assigns each $v_i\ \in \Sigma$ to one value in its domain as defined by possible world $w$. The interpretation of a formula $\theta$, $I_w(\theta)$ is recursively calculated using the associated truth tables of the operators involved, as defined in Table~\ref{tbl:prop}. 

\section{Possible Worlds}
A possible world $w\in W_\sigma$ from the set of all possible worlds $W$ over a language $\Sigma$ is $(v_0,w_0) \land ... \land I(v_n,w_n)$ and is the conjunction of each atom and an associated value from its domain. Possible worlds represent one setting of the variables in the alphabet that could hypothetically hold. A model of a propositional formula $\theta \in \zeta$ is a possible world $w$ in which $\theta$ is evaluated to $top$ (also called satisfying) and is written $w \models \theta$. 

$Mod(\theta)$ denotes the set of possible worlds in which $\theta$ holds -- that is, $Mod(\theta)=\{w|w\models \theta\}$. The operator $\models$ is overloaded so that $\phi \models \psi$ if and only if $Mod(\phi) \subseteq Mod(\psi)$ for $\phi,\psi \in \zeta$.

\section{Conditionals}
\begin{table}
\begin{center}
\begin{tabular}{ c | c c }
  $(\psi|\phi)$& $\phi\models \top$ & $\phi \models \bot$ \\ \hline
 $\psi\models \top$ & verification & non-applicability \\  
 $\psi \models \bot$ & falsification & non-applicability
\end{tabular}
\caption{Evaluation of conditional rules.}
\label{tbl:cond}
\end{center}
\end{table}

Defeasible knowledge is information which is assumed, but not guaranteed, to hold. Many non-monotonic logics treat this notion as a form of typicality. A condition $(\psi|\phi)$ is used to represent the defeasible rule ``if $\phi$ then $\psi$". Following @TODOrefwason1968 we do not use the implication $\leftarrow$ to represent a conditional, and instead opt for what Baratgin (@TODOrefbaratgin2014) called a \textit{deFinetti truth table} (Table~\ref{tbl:cond}). This truth table for conditionals differs from the standard implication in that it treats rules of the form $(\psi|\phi)$ as inapplicable when $\phi \models \bot$ and more closely follows human intuition about how rules are evidenced in the absence of their antecedent. @TODO introduce 3-valued de-finetti.

\subsection{Interpretation of conditionals} \label{ssec:condInterpretation}
The precise interpretation of conditionals is a topic for philosophical and logical debate. Approaches both probabilistic and logical can be used to define precisely what a conditional means in the context of a logical system. In this thesis we adopt adopt @TODOrefs interpretation of conditionals as licenses for implication. 

Thus, the conditional $(\psi|\phi)$ precisely means $\psi \leftarrow \phi \land \lnot \text{ab}$ where $\text{ab}$ is called an abnormality predicate. The abnormality predicate captures an element of uncertainty in the interpretation of the conditional and means that the conditional now reflects the statement ``If $\phi$ and nothing abnormal is known, then $\psi$".

The choice of appropriate value assignments to the abnormality predicate is non-trivial and often requires expert knowledge to design. However, over the course of this thesis we will adopt an algorithmic approach to abnormality creation (Algorithm~\ref{alg:addAB}) that will serve to mimic the hand-designed abnormalities used by \citep{dietz2012computational}, and \citep{breu2019weak}.


\begin{algorithm}[H] \label{alg:addAB}
\SetAlgoLined
\SetKwProg{Fn}{Function}{ is}{end}
\Fn{Create Abnormalities(KB)}
{
\For{$(\psi|\phi) \in \text{KB}[\Delta]$}
{
$k:=$ the lowest natural number for which $\text{ab}_k \notin \text{KB}$\;
$\text{all dependencies}:= [A | (\psi|A) \in \text{KB}'[\Delta]]$\;

\For{$A \in \text{all dependencies}$}
{
$\text{head}:=\psi$\;
$\text{current dependencies}:= \text{all dependencies} - \text{A}$\;
\If{$\text{current dependencies} = \{\}$}
{
$\text{current dependencies}:=\bot$\;
}
$\text{body}:=(\text{current dependencies}_1 \lor ... \lor \text{current dependencies}_n)$\;

\tcc{Add the conditional as a license for implication to the set of rules.}
$\text{KB}'[S]:= \text{KB} \cup (\text{head} \leftarrow A \land \lnot \text{ab}_k)$\;
$\text{KB}'[S]:= \text{KB}'[S] \cup \text{ab}_k \leftarrow \lnot body$\;

}
}
\tcc{Remove all conditionals now that they have been interpreted as licences for implication.}
$\Delta:=\{\}$\;
\Return $\text{KB}'$
}
\caption{\texttt{Conditional to License for Implication}}
\end{algorithm}







\section{Logic Programming}
\subsection{Knowledge Base} \label{ssec:kb}
In propositional logic, a knowledge base $S=\{\phi_1,...,\phi_n\}$ for the language $\Sigma$ is a set of propositional rules from the set of formula $\zeta_\Sigma$. A propositional knowledge base is used to encoded certain knowledge and relationships about the world. $S$ is called consistent only if their exists some possible world $w \in W$ such that every rule in $I_w(KB_{prop})$ evaluates to $\top$.

More generally, a non-monotonic knowledge base $KB=(S, \Delta)$ contains both a set of propositional rules ($S$) and a set of defeasible/conditional rules ($\Delta=\{\Delta_1,...,\Delta_m\}$). A non-monotonic knowledge base tolerates a conditional $(\psi|\phi)\in\Delta$ if and only if there exists some possible world $w\in W$ that verifies $(\psi|\phi)$ and does not falsify any conditional in $\Delta$. $KB$ is said to be consistent if and only if there exists of partition of $\Delta$, $(\Delta_0,...,\Delta_n)$ such that $\Delta_i$ is tolerated by $\Delta_{i+k}$, where $k$ is any natural number not greater than $m$. 

When $KB=(S=\{\textrm{rule}_1,...,\textrm{rule}_n\},\Delta=\{\})$, we will sometimes ignore $\Delta$ and refer only to the value of $S$ whilst still using the term `$KB$'.
%




\section{Non-Monotonic Logics}
In the field of non-monotonic logics, reasoning is represented as a collection of defeasible inferences. Unlike in classical logic, conclusions need not hold in perpetuity, or even in the same model and revision is always possible. Monotonic logics are not capable of describing human reasoning in experiments like the Suppression Task \citep{dietz2012computational} because they lack this revisionist characteristic. @TODOref showed that two-valued logics were not sufficient to model human cognition.

A large number of non-monotonic frameworks exist in the literature \citep{mcdermott1980non}, each applicable to a different subset of cognitive problem space, and each modelling their problem space with various degrees of success. In the simplest formulation, a non-monotonic logic is simply an extension to a classical logic which introduces a preference relation $\rightarrow_p$. This preference relation states that, given some number of derivable facts in a knowledge base, the fact derived using the most preferential rule is to be derived first and cannot be overwritten by a less preferable assignment.  

Although the non-monotonic logics discussed in this chapter have simple extensions to first-order logic (@TODOref), we instead restrict ourselves to a propositional format throughout this thesis.
\section{The Weak Completion Semantics}
\begin{table}
\begin{center}
\begin{tabular}{ c | c c c }
  $\rightarrow$& $\top$ & $u$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $u$ & $\bot$ \\  
 $u$ & $\top$ & $\top$ & $u$\\  
 $\bot$ & $\top$ & $\top$ & $\top$
\end{tabular}
\caption{A table showing the implication operator in 3-valued \L ukasiewicz logic.}
\label{tbl:luk}
\end{center}
\end{table}

The Weak Completion Semantics is a non-monotonic logic which procedurally encodes several well-known cognitive phenomena (@OTDOextend). The WCS makes use of 3-valued \L ukasiewicz logic (Table~\ref{tbl:luk}), rather than Kripke-Kleene logic which has been shown inadequate to model several aspects of cognition (including suppression @TODOref). It adds abnormalities to non-ground inferences, and replaces the classical inference ($\leftarrow$), with a bijective ($\leftrightarrow$). 

The Weak Completion of a program $P$ is defined as follows:

\begin{enumerate}
\item Replace all clauses of the form $A \leftarrow body_1$, ..., $A \leftarrow body_n$ with $A \leftarrow body_1 \lor ... \lor body_n$.
% \item For all undefined variables $x$, add $x \leftarrow \bot$. THIS IS FOR STRONG COMPLETION ONLY
\item Replace all occurrences of $\leftarrow$ with $\leftrightarrow$.
\end{enumerate}

Applying this procedure to $P$ results in $wcP$ which is the weak completion of $P$.

The next requirement to apply the WCS framework is the introduction of a semantic operator $\phi_{SvL}$ \citep{stenning2008interpretation}. Let $J$ be the result of applying the semantics operator to an interpretation $I$ and logic program $P$. Then $J$ is defined as follows:

\[
\begin{split}
J^\top = \{ & A | \textrm{ there exists a clause } A\leftarrow Body \in P \\ & \textrm{ with } I(Body) = \top\}
\end{split}
\]
\[
\begin{split}
J^\bot = \{ &  A | \textrm{ there exists a clause } A \leftarrow Body \in P \\
           & \textrm{ and for all clauses } A \leftarrow Body \in P \\ & \textrm{ we find } I(Body) = \bot\}
\end{split}
\]

%this might not be right? Should it say I or J? @TODO
Using $I=<\emptyset, \emptyset>$, the least model of $P$ ($\textrm{lm}_\textrm{\L}$wc$P$) can be calculated by iterating $\phi_{SvL,P}$.

\section{Reiter's Default Logic} \label{ssec:reiter}
Reteir's Default Logic \citep{reiter1980logic} is a non-monotonic framework which allows us to divide the inferential capabilities of a system into those facts and inference rules which are always true (as in classical logic) and those which are are usually true. The second type of inference is the eponymous default rule.

Inferences from the set of immutable facts $S$ are made as with propositional knowledge bases, with the addition of the conclusion of any previously evaluated default rules. The set of default rules $d$ consists rules of the form:

\[\frac{\textrm{prerequisite}:\textrm{ justification}_1, \textrm{ ...}, \textrm{ justification}_n}{\textrm{conclusion}}\]

Where \textit{prerequisite}, $\textit{justification}_i$, and \textit{conclusion} are propositional logic clauses. A \textit{conclusion} is valid and added to the set of known variables in $S$ if and only if \textit{prerequisite} holds and no clause $\textit{justification}_i$ holds.


A default rule may be applied to a theory if it is entailed by the theory and all of its justifications and conclusions are consistent with the theory. When a default rule is applied, its consequence is added to the background theory.

Formally, inferences in default logic are calculated as follows:



\begin{algorithm}[H] \label{alg:reiter}
\SetAlgoLined
\SetKwProg{Fn}{Function}{ is}{end}
\Fn{$e$($\bar{p}$)}
{
\tcc{Current theory.}
$T:=S$\;
\tcc{Set of defaults already applied.}
$A:=\{\}$\;
\While{There exists a default rule $d$ that is not in $A$ and is applicable to $T$}
{
Add the conclusion of $d$ to $T$\;
Add 	$d$ to $A$\;
}
\If{$T$ is consistent with all justifications of every default $d \in A$}
{
$T$ is a valid extension\;
}
}

\caption{Algorithmic addition of extensions to a Reiter's Knowledge Base.}
\end{algorithm}

It should be immediately apparent form this formulation that, for many possible sets of rules in $S$, the output is non-monotonic as is dependent on the order in which default rules are evaluated.

A very significant restriction on reiter's default logic is the complexity of computing all inferences. Even in the simple case of $S={rule_1,...rule_n}$ and $d=\{\}$, the set of possible inferences is potential infinitely large, and even the set of non-trivial inferences is computationally infeasible @TODOref. When default rules are included in this computation the complexity of calculating all possible inferences for all possible default rule application sequences quickly becomes intractable for all but the most basic logic programs. With this limitation in mind, we restrict propositional rules to those in the form $a\leftarrow\phi$ where $a$ is an atomic head. Further, we restrict the set of default rules to those of the form $\frac{B:C}{a}$ where $a$ is a literal.

The closed world assumption $\frac{: \lnot \bot}{\bot}$ states that all information which is not known to be true is assumed to be false. The closed world assumption can be used to ensure that every variable $v_i \in I_w(\Sigma) \models \top \lor bot$.