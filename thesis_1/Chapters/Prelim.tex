\chapter{Mathematical Preliminaries}\label{chp:prelim} 
\section{Propositional Logic}\label{ssec:propLog}

\begin{table}
\begin{center}


\begin{tabular}{ c | c c }
  $\land$& $\top$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $\bot$ \\  
 $\bot$ & $\bot$ &  $\bot$
\end{tabular}
\quad
\begin{tabular}{ c | c c }
  $\lor$& $\top$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $\top$ \\  
 $\bot$ & $\top$ &  $\bot$
\end{tabular}
\quad
\begin{tabular}{ c | c }
  $\lnot$& \\ \hline
 $\top$ & $\bot$ \\  
 $\bot$ & $\top$
\end{tabular}

\begin{tabular}{ c | c c }
  $\rightarrow$& $\top$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $\bot$ \\  
 $\bot$ & $\top$ &  $\top$
\end{tabular}
\quad
\begin{tabular}{ c | c c }
  $\leftarrow$& $\top$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $\bot$ \\  
 $\bot$ & $\top$ &  $\top$
\end{tabular}

\caption{Truth tables for standard operators in propositional logic.}
\label{tbl:prop}

\end{center}
\end{table}

Propositional logic is one of the simplest classical logics and concerns itself with binary truth values. $\top$ denotes a tautology, and $\bot$ denotes a contradiction. An alphabet $\Sigma=\{v_1,...,v_n\}$ defines the set of atoms available to the language. Every atom $v_i \in \Sigma$ has the domain $\{v_i, \bar{v_i}\}$. An (atom, domain) pair which associates an atom with a value in its domain is called a literal.

A formula $\theta \in \zeta$ from set of all formuli $\zeta$ is defined recursively over all conjunction $\land$, disjunction $\lor$, and negation $\lnot$ operations as follows:

\[
\theta = \{ v_i \in \Sigma | \lnot \theta | \theta \lor \theta | \theta \land \theta \}
\]


The material implication $(\psi \leftarrow \phi)$ precisely substitutes for the formula $(\lnot \psi \lor \phi)$ and is often used, classically to denote an ``if $\phi$ then $\psi$" relationship between variables. However, in Section~\ref{ssec:condi} other interpretations of the "if $\phi$ then $\psi$" relationship are examined in a non-monotonic setting.

An interpretation of $\Sigma$, $I_w(\Sigma)$ assigns each $v_i\ \in \Sigma$ to one value in its domain as defined by possible world $w$. The interpretation of a formula $\theta$, $I_w(\theta)$ is recursively calculated using the associated truth tables of the operators involved, as defined in Table~\ref{tbl:prop}. 

\section{Possible Worlds}
A possible world $w\in W_\sigma$ from the set of all possible worlds $W$ over a language $\Sigma$ is $(v_0,w_0) \land ... \land I(v_n,w_n)$ and is the conjunction of each atom and an associated value from its domain. Possible worlds represent one setting of the variables in the alphabet that could hypothetically hold. A model of a propositional formula $\theta \in \zeta$ is a possible world $w$ in which $\theta$ is evaluated to $\top$ (also called satisfying) and is written $w \models \theta$. 

$Mod(\theta)$ denotes the set of possible worlds in which $\theta$ holds -- that is, $Mod(\theta)=\{w|w\models \theta\}$. The operator $\models$ is overloaded so that $\phi \models \psi$ if and only if $Mod(\phi) \subseteq Mod(\psi)$ for $\phi,\psi \in \zeta$.

A set of propositional clauses $W$ is called \textit{deductively closed}, written $\text{th}(W)$ if it contains every formula $\phi$ that can be logically deduced from $W$. 

\section{Conditionals} \label{ssec:condi}
\begin{table}
\begin{center}
\begin{tabular}{ c | c c c }
  $(\psi|\phi)$& $\phi\models \top$ & $\phi \models u$ & $\phi \models \bot$ \\ \hline
 $\psi\models \top$ & verification &  non-applicability & non-applicability \\  
  $\psi\models u$ & verification &  non-applicability & non-applicability \\ 
 $\psi \models \bot$ & falsification &  non-applicability & non-applicability
\end{tabular}
\caption{Evaluation of conditional rules.}
\label{tbl:cond}
\end{center}
\end{table}

Defeasible knowledge is information which is assumed, but not guaranteed, to hold. Many non-monotonic logics treat this notion as a form of typicality. A condition $(\psi|\phi)$ is used to represent the defeasible rule ``if $\phi$ then $\psi$". Following \cite{wason1968reasoning} we do not use the implication $\leftarrow$ to represent a conditional, and instead opt for a three-valued interpretation of what \cite{baratgin2014new} called a \textit{deFinetti truth table} (Table~\ref{tbl:cond}). This truth table for conditionals differs from the standard implication in that it treats rules of the form $(\psi|\phi)$ as inapplicable when $\phi \models \bot$ or $\phi \models u$ and more closely follows human intuition about how rules are evidenced in the absence of their antecedent.

\subsection{Interpretation of conditionals} \label{ssec:condInterpretation}
The precise interpretation of conditionals is a topic for philosophical and logical debate. Approaches both probabilistic and logical can be used to define precisely what a conditional means in the context of a logical system. In this thesis we adopt adopt \cite{stenning2008interpretation}'s interpretation of conditionals as licenses for implication. 

Thus, the conditional $(\psi|\phi)$ precisely means $\psi \leftarrow \phi \land \lnot \text{ab}$ where $\text{ab}$ is called an abnormality predicate. The abnormality predicate captures an element of uncertainty in the interpretation of the conditional and means that the conditional now reflects the statement ``If $\phi$ and nothing abnormal is known, then $\psi$".

The choice of appropriate value assignments to the abnormality predicate is non-trivial and often requires expert knowledge to design. However, over the course of this thesis we will adopt an algorithmic approach to abnormality creation (Algorithm~\ref{alg:addAB}) that will serve to mimic the hand-designed abnormalities used by \cite{dietz2012computational}, and \cite{breu2019weak}.


\begin{algorithm}[H] \label{alg:addAB}
\SetAlgoLined
\SetKwProg{Fn}{Function}{ is}{end}
\Fn{Create Abnormalities(KB)}
{
\For{$(\psi|\phi) \in \text{KB}[\Delta]$}
{
$k:=$ the lowest natural number for which $\text{ab}_k \notin \text{KB}$\;
$\text{all dependencies}:= [A | (\psi|A) \in \text{KB}'[\Delta]]$\;

\For{$A \in \text{all dependencies}$}
{
$\text{head}:=\psi$\;
$\text{current dependencies}:= \text{all dependencies} - \text{A}$\;
\If{$\text{current dependencies} = \{\}$}
{
$\text{current dependencies}:=\bot$\;
}
$\text{body}:=(\text{current dependencies}_1 \lor ... \lor \text{current dependencies}_n)$\;

\tcc{Add the conditional as a license for implication to the set of rules.}
$\text{KB}'[S]:= \text{KB} \cup (\text{head} \leftarrow A \land \lnot \text{ab}_k)$\;
$\text{KB}'[S]:= \text{KB}'[S] \cup \text{ab}_k \leftarrow \lnot body$\;

}
}
\tcc{Remove all conditionals now that they have been interpreted as licences for implication.}
$\Delta:=\{\}$\;
\Return $\text{KB}'$
}
\caption{\texttt{Conditional to License for Implication}}
\end{algorithm}







\section{Logic Programming}
\subsection{Knowledge Base} \label{ssec:kb}
In propositional logic, a knowledge base $S=\{\phi_1,...,\phi_n\}$ for the language $\Sigma$ is a set of propositional rules from the set of formula $\zeta_\Sigma$. A propositional knowledge base is used to encoded certain knowledge and relationships about the world. $S$ is called \textit{consistent} only if there exists some possible world $w \in W$ such that every rule in $I_w(KB_{prop})$ evaluates to $\top$.

More generally, a non-monotonic knowledge base $KB=(S, \Delta)$ contains both a set of propositional rules ($S$) and a set of defeasible/conditional rules ($\Delta=\{\Delta_1,...,\Delta_m\}$). A non-monotonic knowledge base tolerates a conditional $(\psi|\phi)\in\Delta$ if and only if there exists some possible world $w\in W$ that verifies $(\psi|\phi)$ and does not falsify any conditional in $\Delta$. $KB$ is said to be consistent if and only if there exists of partition of $\Delta$, $(\Delta_0,...,\Delta_n)$ such that $\Delta_i$ is tolerated by $\Delta_{i+k}$, where $k$ is any natural number not greater than $m$. 

When $KB=(S=\{\textrm{rule}_1,...,\textrm{rule}_n\},\Delta=\{\})$, we will sometimes ignore $\Delta$ and refer only to the value of $S$ whilst still using the term `$KB$'.
%




\section{Non-Monotonic Logics}
In the field of non-monotonic logics, reasoning is represented as a collection of defeasible inferences. Unlike in classical logic, conclusions need not hold in perpetuity, or even in the same model and revision is always possible. Monotonic logics are not capable of describing human reasoning in experiments like the Suppression Task \citep{dietz2012computational} because they lack this revisionist characteristic. \cite{ragni2016two} showed that two-valued logics were not sufficient to model human cognition.

A large number of non-monotonic frameworks exist in the literature \citep{mcdermott1980non}, each applicable to a different subset of cognitive problem space, and each modelling their problem space with various degrees of success. In the simplest formulation, a non-monotonic logic is an extension to a classical logic which introduces a preference relation $\leftarrow_p$. This preference relation states that, given some number of derivable facts in a knowledge base, the fact derived using the most preferential rule is to be derived first and cannot be overwritten by a less preferable assignment.  

Although the non-monotonic logics discussed in this chapter have simple extensions to first-order logic, we instead restrict ourselves to a propositional format throughout this thesis.
\section{The Weak Completion Semantics} \label{ssec:wcs}
\begin{table}
\begin{center}
\begin{tabular}{ c | c c c }
  $\rightarrow$& $\top$ & $u$ & $\bot$ \\ \hline
 $\top$ & $\top$ & $u$ & $\bot$ \\  
 $u$ & $\top$ & $\top$ & $u$\\  
 $\bot$ & $\top$ & $\top$ & $\top$
\end{tabular}
\caption{A table showing the implication operator in 3-valued \L ukasiewicz logic.}
\label{tbl:luk}
\end{center}
\end{table}

The Weak Completion Semantics is a non-monotonic logic which procedurally encodes several well-known cognitive phenomena. The WCS makes use of 3-valued \L ukasiewicz logic (Table~\ref{tbl:luk}), rather than Kripke-Kleene logic which has been shown inadequate to model several aspects of cognition (including suppression \citep{dietz2012computational}). It adds abnormalities to non-ground inferences, and replaces the classical inference ($\leftarrow$), with a bijective ($\leftrightarrow$). 

The Weak Completion of a program $P$ is defined as follows:

\begin{enumerate}
\item Replace all clauses of the form $A \leftarrow body_1$, ..., $A \leftarrow body_n$ with $A \leftarrow body_1 \lor ... \lor body_n$.
% \item For all undefined variables $x$, add $x \leftarrow \bot$. THIS IS FOR STRONG COMPLETION ONLY
\item Replace all occurrences of $\leftarrow$ with $\leftrightarrow$.
\end{enumerate}

Applying this procedure to $P$ results in $\text{wc }P$ which is the \textit{weak completion} of $P$.

The next requirement to apply the WCS framework is the introduction of a semantic operator $\phi_{SvL}$ \citep{stenning2008interpretation}. Let $J$ be the result of applying the semantics operator to an interpretation $I$ and logic program $P$. Then $J$ is defined as follows:

\[
\begin{split}
J^\top = \{ & A | \textrm{ there exists a clause } A\leftarrow Body \in P \\ & \textrm{ with } I(Body) = \top\}
\end{split}
\]
\[
\begin{split}
J^\bot = \{ &  A | \textrm{ there exists a clause } A \leftarrow Body \in P \\
           & \textrm{ and for all clauses } A \leftarrow Body \in P \\ & \textrm{ we find } I(Body) = \bot\}
\end{split}
\]

%this might not be right? Should it say I or J? @TODO
Using $I=<\emptyset, \emptyset>$, the least model of $P$ ($\textrm{lm}_\textrm{\L}$wc$P$) can be calculated by iterating $\phi_{SvL,P}$.

\section{Reiter's Default Logic} \label{ssec:reiter}
Reteir's Default Logic \citep{reiter1980logic} is a non-monotonic framework which allows us to divide the inferential capabilities of a system into those facts and inference rules which are always true (as in classical logic) and those which are are usually true. The second type of inference is the eponymous default rule.

A Reiter Default Theory $(W,D)$ consists of a background theory $W$, and a set of default rules
$D$. For our purposes we will restrict both to a propositional, rather than a first-order logic domain. 

The set of default rules $D$ consists of a set of tritonic clauses of the form $\delta=\frac{\text{pre}(\delta):\text{just}(\delta)}{\text{cons}(\delta)}$. Where $\text{pre}(\delta)$ is a propositional clause called the precondition, $\text{just}(\delta)$ is a set of propositional clauses and is called the justification, and $\text{cons}(\delta)$ is a propositional clause called the consequence. To maintain consistency, we restrict our background theory to propositional clauses of the form $(\text{head}\leftarrow \text{body})$ and restrict $D$ so that, for any $\delta \in D$, $\text{cons}(\delta)$ is of the form $(\text{head}\leftarrow \text{body})$.%, where $\text{head}$ is a literal, and $\text{body}$ is a clause $\theta$ recursively defined by $\theta = \{ v_i \in \Sigma | \lnot \theta | \theta \lor \theta | \theta \land \theta\}$.


A default $\delta$ is \textit{applicable} to a deductively closed set $\text{th}(W)$ if and only if $\text{pre}(\delta) \in \text{th}(W)$ and there exists no $\text{just}_i(\delta) \in \text{just}(\delta)$ such that $\lnot \text{just}(\delta) \in th(W)$.

A default process $\Pi=(\delta_1,...,\delta_n)$ consists of a sequence of default rules, $\delta_i\in D\}$. Following \cite{ragni2017formal}, we define the sets $\text{In}(\Pi)=\{\text{th}(W \cup \text{cons}(\delta)|\delta \in \Pi)$ and $\text{Out}(\Pi)=\{\lnot A|A \in \text{just}(\delta), \delta \in \Pi\}$. A default process is called \textit{successful} if and only if $\text{In}(\Pi)\cap \text{Out}(\Pi)=\emptyset$. A default process if called \textit{closed} if and only if there exists no $\delta \in D$, where $\delta$ is applicable to $\text{In}(\Pi)$ and $\delta \not\in \Pi$. The set $E$ is called an extension of default process $D$ if and only if $E=\text{In}(\Pi)$, for some successful closed process $\Pi$. 

We write $W\models_\text{D}^\text{Reiter} \psi$ if and only if $\psi \in \bigcap \epsilon$, where $\epsilon$ is the set of all valid extensions of the default theory $(W,D)$.


It should be immediately apparent form this formulation that, for many possible sets of rules in default theories, the number of extensions is non-monotonic as it is dependent on the number of orders in which default rules are applied successfully. A very significant restriction on reiter's default logic is the complexity of computing deductively closed sets.

The closed world assumption $\frac{: \lnot \bot}{\bot}$ states that all information which is not known to be true is assumed to be false. The closed world assumption can be used to ensure that, for every variable $v_i \in \Sigma$, $I_w(v_i) \models \top$ or $I_w(v_i) \models \bot$.



